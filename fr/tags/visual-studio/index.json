[{"content":"Il n\u0026rsquo;est pas rare lors de d√©veloppements √† plusieurs que chacun ait besoin de sa propre configuration afin de pouvoir d√©velopper convenablement en local.\nLe probl√®me qui peut arriver et qu\u0026rsquo;un d√©veloppeur commit par inadvertance un changement sur un fichier de configuration contenant ses propres donn√©es locals, cela pollue l\u0026rsquo;historique de fichier et pire, cela peut engendrer des probl√®mes chez les autres d√©veloppeurs lors du prochain pull.\nLa technique que j\u0026rsquo;utilise qui a l\u0026rsquo;avantage de fonctionner peu importe la technologie est simplement d\u0026rsquo;utiliser un template de configuration.\nExemple dans le cas de Service Fabric, le fichier contenant l\u0026rsquo;ensemble des configurations du cluster peut √™tre Local.1Node.xml.\nLa proc√©dure consiste simplement √† cr√©er un fichier de r√©f√©rence Local.1Node.template.xml qui contiendra l\u0026rsquo;ensemble des param√®tres par d√©faut et d\u0026rsquo;ignorer sous git le fichier de configuration originel Local.1Node.xml.\n\rA cela j\u0026rsquo;ajoute personnellement une t√¢che msbuild ayant pour objectif de copier le template si aucun fichier de configuration n\u0026rsquo;est pr√©sent avant la build (plus de confort pour les prochains d√©veloppeurs). Dans le .csproj, .sfproj ou autre il suffit d\u0026rsquo;ajouter cette t√¢che pre-build :\n1 2 3 4 5 6 7  \u0026lt;Project ...\u0026gt; ... \u0026lt;Target Name=\u0026#34;BeforeBuild\u0026#34;\u0026gt; \u0026lt;Copy SourceFiles=\u0026#34;ApplicationParameters\\Local.1Node.template.xml\u0026#34; DestinationFiles=\u0026#34;ApplicationParameters\\Local.1Node.xml\u0026#34; Condition=\u0026#34;!Exists(\u0026#39;ApplicationParameters\\Local.1Node.xml\u0026#39;)\u0026#34; /\u0026gt; \u0026lt;/Target\u0026gt; ... \u0026lt;/Project\u0026gt;   voil√† tout simplement!\n","description":"","id":8,"section":"posts","tags":["visual studio","dotnet","quality","msbuild","tips"],"title":"[Dev] Comment √©viter les commits accidentels sur les fichiers de configuration","uri":"https://blog.jeremylandon.com/fr/2020/06/28/dev-how-to-prevent-accidental-commits-on-the-config-files/"},{"content":"J\u0026rsquo;ai eu besoin √† de nombreuses reprises de r√©aliser des polling dans mes tests d\u0026rsquo;int√©grations avec Postman. Je vous partage aujourd\u0026rsquo;hui les fonctions que j\u0026rsquo;utilise pour √ßa üçª\nLa logique sera stock√©e en variable globale afin de pouvoir √™tre utilis√©e dans plusieurs requ√™tes.\nCette technique permettant de partager des fonctions est d√©taill√©e sur le blog postman √† l\u0026rsquo;adresse suivante : https://blog.postman.com/api-testing-tips-from-a-postman-professional/\r Le code ci-dessous est √† placer dans une requ√™te \u0026ldquo;fake\u0026rdquo; (ex: type Get sur https://postman-echo.com/get) dans la section Pre-request Script.\n La fonction de polling est utilisable dans la section Test de la requ√™te sur lequel le polling sera r√©alis√© :\n Dans cet exemple la requ√™te sera appel√©e tant que le code HTTP de r√©ponse ne sera pas 200, avec un d√©lai de 1sec entre chaque tentative et au maximum 10 fois.\nPour que le polling fonctionne la requ√™te devra √™tre lanc√©e via le Collection Runner:\r Et voil√†!\nSources  https://gist.github.com/Golapadeog/0494d9484c397beb39df3382cddb536d  Documentation  https://blog.postman.com/api-testing-tips-from-a-postman-professional/ https://learning.postman.com/docs/postman/collection-runs/starting-a-collection-run/  ","description":"","id":9,"section":"posts","tags":["postman","javascript","test","quality"],"title":"[Postman] R√©aliser un polling avec Postman","uri":"https://blog.jeremylandon.com/fr/2020/06/15/postman-realiser-un-polling-avec-postman/"},{"content":"Azure DevOps (Travis, Google Cloud build \u0026amp; co) proposent des agents de build en mode Saas (h√©berg√©s par un tier).\nIls sont tr√®s pratique car il n\u0026rsquo;y a aucune infrastructure √† g√©rer mais ils peuvent poser probl√®me lorsque la build doit se faire sur un service prot√©g√©.\nEn effet les agents √©tant public ils peuvent ne pas avoir les autorisations pour d√©ployer sur un service.\nJ\u0026rsquo;ai rencontr√© le probl√®me avec le service Azure Service Fabric prot√©g√© par un Network Security Group, lors de l\u0026rsquo;ex√©cution de la t√¢che de d√©ploiement cette derni√®re ne se fait pas car la s√©curit√© refuse toutes les ip public.\nSi vous utilisez ExpressRoute le probl√®me ne se pose pas car vous avez une liaison priv√©e avec Azure.\r Solutions Premi√®re solution (qui sera la meilleure dans le futur) Premi√®re solution mais qui n\u0026rsquo;est pas encore faisable aurait √©t√© d\u0026rsquo;ajouter le Service Tag Azure Devops au Network Security Group, mais ce dernier n\u0026rsquo;existe pas encore.\nN√©anmoins il est possible d\u0026rsquo;ajouter le tag AzureCloud en attendant, mais c\u0026rsquo;est un \u0026ldquo;l√©g√®rement\u0026rdquo; bourrin‚Ä¶\nDeuxi√®me solution (bourrin) Seconde solution est d\u0026rsquo;ajouter les plages d\u0026rsquo;ip li√©es √† votre service de build.\nL\u0026rsquo;ensemble des ip public Azure est pr√©sente ici : https://www.microsoft.com/en-us/download/details.aspx?id=56519 et tout les services fournissent ces donn√©es : travis, google cloud\u0026hellip;\nCa marche mais c\u0026rsquo;est pas top, en effet les ip public peuvent changer (la liste est mise √† jour par Microsoft toutes les semaines), donc il va falloir penser √† les mettre √† jour et cela implique d\u0026rsquo;ajouter des plages d\u0026rsquo;ip pour \u0026ldquo;g√©rer tous les cas\u0026rdquo;.\r Troisi√®me solution Troisi√®me solution que je pr√©f√®re est d\u0026rsquo;ajouter lors de la build l\u0026rsquo;ip de l\u0026rsquo;agent de build au Network Security Group.\nSur Azure Devops cela se fait via la t√¢che Azure Cli et il existe des √©quivalents ailleurs (Jenkins: azure-cli, Bamboo: azure-cli-run‚Ä¶).\nVoici le script g√©n√©rique (√† adapter en fonction du service de build utilis√© et des ports requis):\n On oublie pas de supprimer la r√®gle apr√®s la build\n Et voil√†!\nSources  https://gist.github.com/Golapadeog/b418c74123daa8b2973e0078ed7aaa08  Documentation  https://azure.microsoft.com/en-us/services/expressroute/ https://devblogs.microsoft.com/devops/azure-devops-roadmap-update-for-2020-q2/ https://www.microsoft.com/en-us/download/details.aspx?id=56519 https://docs.travis-ci.com/user/ip-addresses/ https://cloud.google.com/compute/docs/faq#find_ip_range https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops https://plugins.jenkins.io/azure-cli/  ","description":"","id":10,"section":"posts","tags":["powershell","azure devops","build","azure","network security group","nsg"],"title":"[Azure] Autoriser un agent de build h√©berg√© √† d√©ployer sur Azure","uri":"https://blog.jeremylandon.com/fr/2020/05/31/azure-autoriser-un-agent-de-build-heberge-a-deployer-sur-azure/"},{"content":"J\u0026rsquo;ai r√©cemment eu besoin de limiter l\u0026rsquo;utilisation d\u0026rsquo;une portion de mon code entre diff√©rents services (√† la mani√®re d\u0026rsquo;une s√©maphore).\nJ\u0026rsquo;utilise RedLock.net (lock distribu√©) pour g√©rer la concurrence mais ce dernier ne fait qu\u0026rsquo;un verrou unitaire (concurrence = 1) et donc ne r√©pondait pas √† mon besoin.\nEn parcourant un peu le site RedisLabs j\u0026rsquo;ai pu tomber sur cette algorithme qui propose une impl√©mentation \u0026ldquo;juste\u0026rdquo; (premier arriv√© premier servi) d\u0026rsquo;une semaphore distribu√©e.\nN\u0026rsquo;existant pas d\u0026rsquo;impl√©mentation en .NET j\u0026rsquo;ai du en d√©velopper une moi m√™me.\nVous pouvez retrouver les sources ici: https://github.com/Golapadeog/DSemaphore.net (le package nuget arrivera prochainement)\nUtilisation Dans un premier temps on cr√©√© une factory\n1 2 3 4 5  var connection = ConnectionMultiplexer.Connect(\u0026#34;127.0.0.1:6379\u0026#34;); using (var semaphoreFactory = DSemaphoreFactory.Create(connection)) { // ... }   Qui nous permet d\u0026rsquo;instancier nos s√©maphores.\nA la mani√®re de la classe SemaphoreSlim on indique le maximum de concurrence que l\u0026rsquo;on souhaite\n1 2 3 4 5 6 7 8  int maxCount = 5; await using (var semaphore = semaphoreFactory.CreateSemaphore(\u0026#34;foo\u0026#34;, maxCount)) { foreach (var entity in collection) { // ...  } }   Et il suffit de verrouiller avec la m√©thode WaitAsync.\nVeuillez √† bien mettre un d√©lai d\u0026rsquo;attente \u0026ldquo;coh√©rent\u0026rdquo;. En effet si l\u0026rsquo;un de vos services s\u0026rsquo;arr√™te (exemple: crash syst√®me), il ne pourra pas lib√©rer explicitement son verrou et ce dernier ne sera consid√©r√© comme obsol√®te qu\u0026rsquo;√† la fin du d√©lai indiqu√© (cons√©quence directe : il bloquera inutilement d\u0026rsquo;autres candidats).\r\n1 2 3 4 5  var timeout = TimeSpan.FromSeconds(3); if (await semaphore.WaitAsync(timeout)) { // an action ... }   Et voil√† c\u0026rsquo;est aussi simple que √ßa! üëå\nLimites et recommandations En impl√©mentant l\u0026rsquo;algorithme propos√©e par RedisLabs j\u0026rsquo;ai pu y voir quelques limites (qui sont propre au syst√®me distribu√© et difficilement corrigeables sans apporter de la lourdeur).\n Comme √©nonc√© pr√©c√©demment si votre service s\u0026rsquo;arr√™te pour une raison X et donc n\u0026rsquo;a pas le temps de lib√©rer son v√©rrouillage alors ce dernier ne sera consid√©r√© comme obsol√®te qu\u0026rsquo;√† la fin du d√©lai indiqu√© √† l\u0026rsquo;appel de la m√©thode WaitAsync La v√©rification fonctionne par polling, par d√©faut la fr√©quence est √©tablie √† 10ms, il est possible de la configurer √† la cr√©ation de la s√©maphore. Mais cette fr√©quence provoque une incertitude sur la d√©tection des verrous obsol√®tes. Il est recommand√© d\u0026rsquo;utiliser des timeouts \u0026gt;= 1sec pour ne pas rencontrer de probl√®me. (pour faire simple la pr√©cision permettant de d√©terminer si une semaphore a expir√©e ou non est de +/- la fr√©quence de v√©rification)  Cette solution remplace-t-elle une solution de Lock distribu√©e classique ? En th√©orie oui, car un lock peut √™tre trait√© par une semaphore √† 1.\nEn revanche je ne le recommande pas, m√™me si cette impl√©mentation est tr√®s performante, elle ne l\u0026rsquo;est pas autant que les solutions de lock classique qui ont bien moins de v√©rifications √† faire.\nEn bref c\u0026rsquo;est du code classique: semaphore pour limiter la concurrence et lock pour l\u0026rsquo;emp√™cher.\nA l\u0026rsquo;√©criture de cet article, cette solution n\u0026rsquo;est qu\u0026rsquo;en b√©ta, il reste notamment √† s√©parer la logique entre le d√©lai d\u0026rsquo;attente d\u0026rsquo;une acquisition et le TTL d\u0026rsquo;un verrou.\r Sources  https://github.com/Golapadeog/DSemaphore.net  Documentation  https://redislabs.com/ebook/part-2-core-concepts/chapter-6-application-components-in-redis/6-3-counting-semaphores/6-3-2-fair-semaphores/ https://docs.microsoft.com/en-us/dotnet/api/system.threading.semaphoreslim https://github.com/samcook/RedLock.net  ","description":"J'ai r√©cemment eu besoin de limiter l'utilisation d'une portion de mon code entre diff√©rents services (√† la mani√®re d'une s√©maphore).","id":11,"section":"posts","tags":["dotnet","redis","csharp","performance","concurrence"],"title":"[Redis] Impl√©mentation d'une s√©maphore distribu√©e en .NET","uri":"https://blog.jeremylandon.com/fr/2020/05/17/redis-implementation-dune-semaphore-distribuee-en-dotnet/"},{"content":"Qu\u0026rsquo;est-ce qu\u0026rsquo;un SynchronizationContext ? Le SynchronizationContext permet d\u0026rsquo;applique une logique sur les op√©rations asynchrones et synchrones afin de s\u0026rsquo;adapter √† un contexte voulu.\nPar d√©faut la classe SynchronizationContext n\u0026rsquo;est qu\u0026rsquo;une base de travail, elle ne synchronise rien, elle expose entre autres une m√©thode virtuelle Post qui a pour r√¥le de distribuer un message au contexte (la \u0026ldquo;logique de synchronisation\u0026rdquo; se fera en grande partie ici).\nSi on devait traduire √ßa en pseudo code cela donnerait quelque chose dans le style :\n1 2 3 4 5  async Task Foo() { await Action1(); Action2(); }   Equivaut √†\n1 2 3 4 5 6 7 8 9  Task Foo() { var task = Action1(); var ctx = SynchronizationContext.Current; task.ContinueWith(task) =\u0026gt; ctx.Post((o) =\u0026gt; Action2(), null), TaskScheduler.Current); return task; }   La m√©thode Post peut par exemple\n imbriquer l\u0026rsquo;action dans un lock pour rendre le tout thread-safe mettre en place une semaphore pour limiter le nombre de concurrence fournir des logs \u0026hellip;  bref c\u0026rsquo;est √† adapter au besoin.\nIl existe des impl√©mentations sp√©cifiques de SynchronizationContext utilis√©es nativement en WPF, Winform ou encore ASP.NET afin de s\u0026rsquo;adapter aux probl√©matiques du framework cible.\nDans le cas d\u0026rsquo;ASP.NET l\u0026rsquo;impl√©mentation est faite au travers de la classe interne AspNetSynchronizationContext.\nOn parle ici de ASP.NET et non de ASP.NET Core qui lui a abandonn√© l\u0026rsquo;utilisation du SynchronizationContext.\r Cette impl√©mentation est complexe mais on peut noter comme points notables qu\u0026rsquo;elle est utilis√©e lors de l\u0026rsquo;ex√©cution du code d\u0026rsquo;une page, elle permet entre autres de capture le contexte http et de s\u0026rsquo;assurer que toutes les op√©rations asynchrones se terminant au m√™me moment seront ex√©cut√©es l\u0026rsquo;une apr√®s l\u0026rsquo;autre (m√™me si elles sont sur plusieurs threads diff√©rents).\nCe qui signifie que ceci :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public async Task\u0026lt;ActionResult\u0026gt; Index() { var myCollection = new List\u0026lt;int\u0026gt;(); // a non-thread-safe collection  var tasks = new List\u0026lt;Task\u0026gt;(); for (int i = 0; i \u0026lt; 100000; i++) { var myValue = i; tasks.Add(Task.Run(async () =\u0026gt; { await Task.Delay(new Random().Next(5)); // simulate an action  myCollection.Add(myValue); // add value to a non-thread-safe collection  })); } await Task.WhenAll(tasks); return View(); }   Fonctionne parfaitement en ASP.NET m√™me si la collection List n\u0026rsquo;est pas thread-safe, le SynchronizationContext va effectuer un lock sur chacunes des op√©rations et ainsi il ne peut y avoir de concurrence sur l\u0026rsquo;ajout des √©l√©ments.\nEn revanche en ASP.NET Core, sans ce SynchronizationContext il pourrait y avoir de la concurrence lors de l\u0026rsquo;ajout d\u0026rsquo;√©l√©ments dans la collection, et il sera necessaire de passer sur des collections thread-safe type ConcurrentBag.\nQue fait ConfigureAwait ? ConfigureAwait permet de sp√©cifier si la suite du code doit s\u0026rsquo;ex√©cuter dans le contexte d\u0026rsquo;origine ou non.\nPar d√©faut cela est le cas et cela peut provoquer de gros probl√®mes.\nPar exemple avec WPF o√π les actions seront r√©alis√©es en liaison avec le Thread UI, l\u0026rsquo;interface peut √™tre bloqu√©e/saccad√©e car les actions bloqueront de mani√®re s√©quentiel le Thread UI pour capturer le contexte et continuer la suite du code.\nConcr√®tement avec un ConfigureAwait(false) le SynchronizationContext n\u0026rsquo;est plus captur√©.\n1 2 3 4 5 6 7  Debug.WriteLine(SynchronizationContext.Current != null); // true  await Task.Delay(10); // an action Debug.WriteLine(SynchronizationContext.Current != null); // true  await Task.Delay(10).ConfigureAwait(false); // an action Debug.WriteLine(SynchronizationContext.Current != null); // /!\\ false   Cela implique qu\u0026rsquo;il n\u0026rsquo;est plus possible d\u0026rsquo;acc√©der aux donn√©es offertes par le contexte, par exemple en ASP.NET avec le HttpContext\n1 2 3 4 5 6 7  Debug.WriteLine(System.Web.HttpContext.Current != null); // true  await Task.Delay(10); // an action Debug.WriteLine(System.Web.HttpContext.Current != null); // true  await Task.Delay(10).ConfigureAwait(false); // an action Debug.WriteLine(System.Web.HttpContext.Current != null); // /!\\ false   Ce dernier n\u0026rsquo;est plus accessible comme tout le reste.\nQuand utiliser le ConfigureAwait(false) ? Comme nous venons de le voir: lorsque vous n\u0026rsquo;avez pas besoin du contexte.\nLa majorit√© du temps le contexte est inutile et il convient de ne pas le r√©cup√©rer. Il faudra donc penser √† chaque action asynchrone appeler ConfigureAwait(false).\nIl existe des fa√ßons bien moins lourdes pour g√©rer la non r√©cup√©ration du contexte que nous verrons dans un prochain post.\rJe suis sous .NET Core, il n\u0026rsquo;y a pas de SynchronizationContext, je peux donc me passer de l\u0026rsquo;appel √† ConfigureAwait En th√©orie oui, mais il arrive que non et ceux pour principalement 2 raisons:\n Si le code est pr√©vu pour √™tre utilis√© aussi sur le framework .NET alors il convient de continuer √† g√©rer les contextes M√™me si de base .NET Core n\u0026rsquo;impl√©mente pas de SynchronizationContext rien n\u0026rsquo;emp√™che d\u0026rsquo;en impl√©menter un (exemple Blazor en poss√®de un).  La seule situation o√π cette \u0026ldquo;lourdeur\u0026rdquo; n\u0026rsquo;est pas √† prendre en compte et sur vos propres applications o√π vous maitrisez l\u0026rsquo;existence/non existence du SynchronizationContext, et si la non gestion du contexte ne d√©grade pas ou tr√®s peu les performances (comme c\u0026rsquo;est le cas sur ASP.NET Core).\nAnecdote Dans le cas o√π vous d√©veloppez une librairie externe pr√©parez vous √† certains casses t√™tes \u0026ldquo;fonctionnels\u0026rdquo; üî•.\nJ\u0026rsquo;ai voulu √©crire ce post il y a plusieurs mois, lorsque j\u0026rsquo;ai vu ce code sur le net:\n1 2 3 4 5 6 7  public static async Task ForEachAsync\u0026lt;TEntity\u0026gt;(this IEnumerable\u0026lt;TEntity\u0026gt; entities, Func\u0026lt;TEntity, Task\u0026gt; action) { foreach (var item in entities) { await action(item).ConfigureAwait(false); } }   Comme son nom l\u0026rsquo;indique elle permet de simplement de faire un foreach async en inline.\nQuel est le probl√®me ?\nLe probl√®me est que cette m√©thode ne respecte pas selon moi un principe subjectif qui me tient √† coeur qui est le POLS (principe de moindre surprise = une m√©thode fait ce qu\u0026rsquo;on pense qu\u0026rsquo;elle va faire).\nPersonnellement je m\u0026rsquo;attend √† ce qu\u0026rsquo;elle fasse un simple foreach (comme son nom et son existence m√™me semble l\u0026rsquo;indiquer) mais elle traite aussi sur l\u0026rsquo;utilisation du contexte avec un comportement qui n\u0026rsquo;est pas celui par d√©faut.\nEt voici ce qui peut arriver:\n1 2 3 4 5  await myHeaders.ForEachAsync(async s =\u0026gt; { var userLang = System.Web.HttpContext.Current.Request.Headers[s]; // throw NullReferenceException on the second iteration  await DoWorkAsync(userLang); });   Comme le contexte n\u0026rsquo;est pas r√©cup√©r√© √† la fin de la premi√®re it√©ration, si l\u0026rsquo;action N¬∞2 n√©cessite une donn√©e issue du contexte elle ne pourra pas la r√©cup√©rer üïµÔ∏è‚Äç‚ôÇÔ∏è\nBon courage pour comprendre l\u0026rsquo;origine du probl√®me si vous n\u0026rsquo;avez pas acc√®s aux sources et sur des m√©thodes plus complexes\u0026hellip; en bref il faut vraiment r√©flechir √† si oui ou non notre m√©thode aurait besoin du contexte et si oui pouvoir donner la possibilit√© √† l\u0026rsquo;utilisateur de l\u0026rsquo;utiliser ou non.\nConclusion Il y a encore √©norm√©ment de choses √† dire sur le SynchronizationContext, cela fera peut √™tre l\u0026rsquo;objet d\u0026rsquo;autres posts, je vous laisse comme d\u0026rsquo;habitude quelques sources en fin de post pour aller un peu plus loin.\nAvec la mont√©e croissante de l\u0026rsquo;adoption d\u0026rsquo;ASP.NET Core les probl√©matiques autour du SynchronizationContext sont de moins en moins primordiales.\nPar exemple l\u0026rsquo;√©quipe en charge d\u0026rsquo;ASP.NET Core a fait le choix de ne plus le prendre en compte pour une bonne partie de leur code afin de gagner en lisibilit√© quitte √† ce que cela induit une baisse de performance.\nA noter que cette baisse de performance est extr√™mement minime voir inexistante d√ª au simple fait qu\u0026rsquo;appeler ConfigureAwait(false) consomme des ressources.\nSources Documentation  https://devblogs.microsoft.com/dotnet/configureawait-faq/ https://blog.stephencleary.com/2017/03/aspnetcore-synchronization-context.html https://docs.microsoft.com/en-us/archive/msdn-magazine/2011/february/msdn-magazine-parallel-computing-it-s-all-about-the-synchronizationcontext https://referencesource.microsoft.com/#system.web/AspNetSynchronizationContext.cs https://en.wikipedia.org/wiki/Principle_of_least_astonishment  ","description":"Le SynchronizationContext permet d'applique une logique sur les op√©rations asynchrones et synchrones afin de s'adapter √† un contexte voulu","id":12,"section":"posts","tags":["dotnet","csharp","performance"],"title":"[.NET] SynchronizationContext, ConfigureAwait et optimisations","uri":"https://blog.jeremylandon.com/fr/2020/05/03/dotnet-synchronizationcontext-configureawait-et-optimisations/"},{"content":"J\u0026rsquo;ai eu la mauvaise surprise le mois dernier de voir tous mes abonnements sur android se faire rembourser automatiquement au bout de 3 jours.\nCela est d√ª √† Google Play Billing Library v2 qui oblige √† valider chaque souscription (√† l\u0026rsquo;image d\u0026rsquo;IOS) dans les 3 jours, sinon =\u0026gt; remboursement de l\u0026rsquo;utilisateur üí∏.\nCela est pr√©vu depuis bien longtemps et l\u0026rsquo;√©quipe r√©sponsable de la biblioth√®que a tr√®s bien communiqu√© √† ce sujet.\nMAIS l\u0026rsquo;√©quipe de Flutter est √† la tra√Æne et la documentation porte vraiment √† confusion, en effet il est indiqu√© que la validation n\u0026rsquo;est requise que pour IOS (sous entendant qu\u0026rsquo;elle est automatiquement faite sur android).\nif (Platform.isIOS) {\n// Mark that you\u0026rsquo;ve delivered the purchase. Only the App Store requires\n// this final confirmation.\nInAppPurchaseConnection.instance.completePurchase(purchase);\n}\r Mais rien n\u0026rsquo;est fait et il faudra en effet valider comme sur IOS chacune des souscriptions (la documentation est donc actuellement fause\u0026hellip;).\nA l\u0026rsquo;√©criture de l\u0026rsquo;article (plus d\u0026rsquo;un mois apr√®s la mise en application de la r√®gle des 3 jours) il est encore indiqu√© que la validation n\u0026rsquo;est requise que pour IOS‚Ä¶\r Pour r√©gler le probl√®me il faudra avant tout de chose passer sur une version \u0026gt;= 0.3.0 de in_app_purchase et tout simplement appeler la m√©thode completePurchase.\n1 2 3  if (purchaseDetails.pendingCompletePurchase) { await InAppPurchaseConnection.instance.completePurchase(purchaseDetails); }   Inutile de v√©rifier la propri√©t√© isAcknowledged (pour √©viter les requ√™tes inutiles), la m√©thode le fait d\u0026rsquo;elle m√™me.\r Voil√†!\nSources Documentation  https://github.com/flutter/plugins/blob/master/packages/in_app_purchase/lib/src/in_app_purchase/google_play_connection.dart https://developer.android.com/google/play/billing/billing_library_releases_notes https://pub.dev/documentation/in_app_purchase https://pub.dev/packages/in_app_purchase  ","description":"","id":13,"section":"posts","tags":["flutter","dart","ios","android","mobile"],"title":"[Flutter] Comment valider une souscription avec in_app_purchase ?","uri":"https://blog.jeremylandon.com/fr/2020/04/27/flutter-comment-valider-une-souscription-avec-in_app_purchase/"},{"content":"On m\u0026rsquo;a r√©cemment pos√© la question sur \u0026ldquo;quelle est la \u0026ldquo;meilleure\u0026rdquo; m√©thode pour supprimer les √©l√©ments d\u0026rsquo;une collection √† taille variable\u0026rdquo;.\n myCollection.Clear() myCollection = new List() myCollection = null  Selon moi comme toujours il n\u0026rsquo;y a pas de \u0026ldquo;meilleure\u0026rdquo; solution ou m√™me de \u0026ldquo;m√©thode magique\u0026rdquo;, tout d√©pend de ce qu\u0026rsquo;on veut r√©ellement faire et ce qu\u0026rsquo;on veut transmettre comme message aux prochains d√©veloppeurs qui liront le code.\nNous ne traiterons pas le cas des collections thread safe de type ConcurrentBag \u0026amp; co. o√π la notion de concurrence rentre en jeu (en excluant ce point la logique reste identique).\r Avant toutes choses du point de vue de la performance et en prenant en crit√®re la volont√© de supprimer les √©l√©ments du tableau sans aller dans la micro-optimisation, les 3 m√©thodes peuvent √™tre consid√©r√©e comme √©quivalente = les √©l√©ments seront supprim√©s par le GC.\nAlors peu importe la solution √ßa ne change rien ? Non, car m√™me si la finalit√© sur les objets de la collection est la m√™me, au globale le r√©sultat est diff√©rent.\nVoici les classes utilis√©es dans les exemples, ces derni√®res ne sont utilis√©es que pour obtenir facilement un status visible de leur destruction.\nFoo\rTestList\rGetTestData\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Foo { private readonly int _id; public Foo(int id) { _id = id; } ~Foo() { Console.WriteLine($\u0026#34;Free Foo_{_id}\u0026#34;); } }   \r\r1 2 3 4 5 6 7  public class TestList\u0026lt;T\u0026gt; : List\u0026lt;T\u0026gt; { ~TestList() { Console.WriteLine(\u0026#34;Free TestList\u0026#34;); } }   \r\r1 2 3 4 5 6 7 8 9 10  private static TestList\u0026lt;Foo\u0026gt; GetTestData() { var foos = new TestList\u0026lt;Foo\u0026gt;(); for (var i = 0; i \u0026lt; 2; i++) { foos.Add(new Foo(i)); } return foos; }   \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"297e4547df24e9d8\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r\nnull Assigner la collection √† null revient √† pousser un r√©f√©rence null et √† l\u0026rsquo;assigner √† notre variable.\nIL_00aa: ldnull\nIL_00ab: stloc.0\r1 2 3 4 5 6 7 8 9  var foos = GetTestData(); foos = null; GC.Collect(); GC.KeepAlive(foos); // Free Foo_1 // Free Foo_0 // Free TestList   Cela signifie que notre collection initiale n\u0026rsquo;est plus rattach√©e aux GC Roots, elle sera donc consid√©r√©e comme morte au prochain passage du GC.\nEt comme cette derni√®re poss√®de des objets rattach√©s qui n\u0026rsquo;ont pas d\u0026rsquo;autres r√©f√©rences ils seront supprim√©s par la m√™me occasion.\nDonc cette m√©thode supprime la collection et les objets rattach√©s.\nIl est strictement inutile d\u0026rsquo;affecter un objet √† null en fin de scope, en effet une fois le scope pass√© l\u0026rsquo;objet n\u0026rsquo;est de fait plus rattach√© aux GC Roots (s\u0026rsquo;il n\u0026rsquo;est pas r√©f√©renc√© ailleurs).\r 1 2 3 4  { var foos = GetTestData(); foos = null; }   Est identique √†\n1 2 3  { var foos = GetTestData(); }   new() Similaire √† la m√©thode pr√©c√©dente √† la diff√©rence que c\u0026rsquo;est une nouvelle instance de classe (=nouvelle r√©f√©rence) qui est pouss√©e dans la pile d\u0026rsquo;√©valuation et non null.\nIL_00aa: newobj\nIL_00ab: stloc.0\r1 2 3 4 5 6 7 8 9  var foos = GetTestData(); foos = new TestList\u0026lt;Foo\u0026gt;(); GC.Collect(); GC.KeepAlive(foos); // Free Foo_1 // Free Foo_0 // Free TestList   Comme avec null, la collection est supprim√©e d√ª au fait que sa r√©f√©rence n\u0026rsquo;est plus li√©e aux GC Roots et par effet de cha√Æne les objets rattach√©s aussi.\nClear() D\u0026rsquo;apr√®s la documentation cette m√©thode \u0026ldquo;supprime tous les √©l√©ments\u0026rdquo;.\nEn v√©rit√© elle remplace les r√©f√©rences avec la collection, c\u0026rsquo;est le GC qui supprimera les objets de la m√©moire.\nLe plus simple est de voir ce qui se passe en vrai.\n1 2 3 4 5 6 7 8  var foos = GetTestData(); foos.Clear(); GC.Collect(); GC.KeepAlive(foos); // Free Foo_1 // Free Foo_0   Contrairement aux m√©thodes pr√©c√©dentes ici on ne touche pas √† la r√©f√©rence de la collection mais seulement aux r√©f√©rences des objets de celle-ci.\nR√©sultat la collection √©tant toujours li√© aux GC Roots, elle n\u0026rsquo;est pas lib√©r√©e mais comme les objets Foo_1 et Foo_2 ne sont plus li√©s √† la collection ni rien d\u0026rsquo;autre ils sont consid√©r√©s comme mort par le GC et ainsi se dernier les lib√®re.\nAussi la collection reste la m√™me de ce fait ces propri√©t√©s acquises dont sa r√©f√©rence ou la capacit√© reste inchang√©e.\nPour rappel une List est simplement un tableau qui se redimensionne √† la hausse automatiquement par r√©affectation.\nPar d√©faut la taille de ce tableau est de 4, si par l\u0026rsquo;accumulation de donn√©es le tableau est de taille 1000, il restera √† 1000 apr√®s le passage de la m√©thode Clear(), cela √©vite de r√©allouer des espaces lors des 1000 prochains ajouts, mais cela implique que vous avez un tableau de taille 1000 en m√©moire.\r R√©sum√©    m√©thode quand ?     null si vous souhaitez lib√©rer la m√©moire allou√©e par la collection et son contenu   new() si vous souhaitez lib√©rer la m√©moire allou√©e par la collection et son contenu tout en cr√©ant une nouvelle instance de la collection et implicitement une nouvelle capacit√© de base   clear() si vous souhaitez lib√©rer uniquement le contenu de la collection, en gardant les propri√©t√©s acquises de la collection    Conclusion Il est important de bien utiliser chacunes des 3 m√©thodes avec pertinence car elles aident √† la compr√©hension du code.\nMicro-optimisation mis √† part, le code doit avant tout √™tre compr√©hensible imm√©diatement.\n si je vois Clear() je comprend de suite la volont√© de supprimer le contenu si je vois new List\u0026lt;T\u0026gt;(400) je comprend directement la volont√© de repartir sur une collection vierge de taille 400 car dans le contexte 400 est la bonne taille et que pr√©c√©demment la collection √©tait bien trop grosse si je vois null c\u0026rsquo;est que la collection ne sera plus utilis√©es plus tard dans le code et potentiellement que sa taille est probl√©matique \u0026hellip;  Si on s\u0026rsquo;attarde sur la micro-optimisation (on parle de seulement quelques Ticks\u0026hellip;) un new List\u0026lt;T\u0026gt;(x) est plus performant qu\u0026rsquo;un Clear() car dans ce dernier un parcours du tableau est requis (avec une compl√©xit√© O(n)), en revanche le message fourni aux prochains d√©veloppeurs peut √™tre ambigu √† la premi√®re lecture (en bref cela ne vaut pas le coup dans la quasi totalit√© des cas).\nSources Documentation  https://en.wikipedia.org/wiki/Tracing_garbage_collection https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals https://github.com/dotnet/runtime/blob/master/src/libraries/System.Collections/src/System/Collections/Generic/SortedList.cs https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1.capacity  ","description":"On m'a r√©cemment pos√© la question sur quelle est la ‚Äúmeilleur‚Äù m√©thode pour supprimer les √©l√©ments d'une collection √† taille variable.","id":14,"section":"posts","tags":["dotnet","csharp","performance","benchmark"],"title":"[.NET] Comment r√©initialiser une collection proprement: clear(), new() ou null ?","uri":"https://blog.jeremylandon.com/fr/2020/04/20/dotnet-comment-reinitialiser-une-collection-proprement-clear-new-ou-null/"},{"content":"Vous avez rencontr√© cette erreur en essayant de cr√©er une nouveau conteneur sur l\u0026rsquo;√©mulateur local de Cosmos DB:\n\u0026ldquo;Sorry, we are currently experiencing high demand in this region, and cannot fulfill your request at this time. We work continuously to bring more and more capacity online, and encourage you to try again\u0026rdquo;\r\nAugmenter le nombre de conteneur Par d√©faut l\u0026rsquo;√©mulateur Cosmos DB ne g√®re que 25 conteneurs de taille fixe ou 5 conteneurs illimit√©s (ou un mixe des deux sachant qu\u0026rsquo;un conteneur de taille illimit√© √©quivaut √† 5 conteneurs de taille fixe).\nIl est possible d\u0026rsquo;augmenter cette limite jusqu\u0026rsquo;√† 250 conteneurs de taille fixe (en acceptant de supprimer toutes ces collections), pour ce faire :\n Quittez l\u0026rsquo;√©mulateur Cosmos: cela prend plusieurs longues minutes =\u0026gt; le plus rapide est d\u0026rsquo;arr√™ter les processus Cosmos DB comme un cochon üêΩ (Azure Cosmos Master Service / Azure Cosmos Server Service / DocumentDB.GatewayService / Microsoft Azure Cosmos Emulator). Supprimez les donn√©es de l\u0026rsquo;√©mulateur en supprimant tous les fichiers de ce dossier: %LOCALAPPDATA%\\CosmosDBEmulator. Lancer l\u0026rsquo;√©mulateur avec les param√®tre PartitionCount \u0026lt;= 250.  1 2 3 4 5 6 7 8 9 10 11  \u0026lt;# kill cosmos like a üêΩ #\u0026gt; taskkill /im \u0026#34;CosmosDB.Emulator.exe\u0026#34; /f taskkill /im \u0026#34;Microsoft.Azure.Cosmos.Server.exe\u0026#34; /f taskkill /im \u0026#34;Microsoft.Azure.Cosmos.Master.exe\u0026#34; /f taskkill /im \u0026#34;Microsoft.Azure.Cosmos.GatewayService.exe\u0026#34; /f \u0026lt;# remove cosmos datas #\u0026gt; Remove-Item \u0026#34;$env:LOCALAPPDATA\\CosmosDBEmulator\\*\u0026#34; -Recurse -Force \u0026lt;# run cosmos with 250 partitions #\u0026gt; \u0026amp; \u0026#34;C:\\Program Files\\Azure Cosmos DB Emulator\\CosmosDB.Emulator.exe\u0026#34; /PartitionCount=250   Voil√†! üëå\nLa limite du nombre de conteneur est mise en place pour limiter les ressources allou√©es √† l\u0026rsquo;√©mulateur.\r Sources Documentation  https://stackoverflow.com/a/51617916/4181832 https://docs.microsoft.com/en-us/azure/Cosmos-db/local-emulator  ","description":"\"Sorry, we are currently experiencing high demand in this region, and cannot fulfill your request at this time. We work continuously to bring more and more capacity online, and encourage you to try again\"","id":15,"section":"posts","tags":["azure","Cosmos","exception"],"title":"[Azure] Comment augmenter le nombre de conteneur sur l'√©mulateur Cosmos DB","uri":"https://blog.jeremylandon.com/fr/2020/04/12/azure-comment-augmenter-le-nombre-de-conteneur-sur-lemulateur-cosmos-db/"},{"content":"Les erreurs HTTP 429 se produisent lorsque la consommation sur un conteneur est sup√©rieure au d√©bit provisionn√©.\nConsommation en RU par seconde  RU provisionn√© par seconde = HTTP 429.\r\nAvant tout de chose, est-ce grave ?\nTout d√©pend de la situation, la finalit√© d\u0026rsquo;une erreur 429 est que la requ√™te n\u0026rsquo;a pas √©t√© ex√©cut√©e, cela peut √™tre probl√©matique dans des contextes o√π la coh√©rence des donn√©es est importante (ex: ajout d\u0026rsquo;un profil utilisateur), mais moins si elle ne l\u0026rsquo;est pas (ex: une vue sur une vid√©o durant un pic de trafic de quelques secondes).\nLes r√©flexes √† adopter Optimiser les requ√™tes Optimiser les RU Le RU (unit√© de requ√™te/request unit) est l\u0026rsquo;unit√© de devise du d√©bit. Elle est calcul√©e via diff√©rents facteurs qui sont tr√®s bien d√©taill√©s sur le site de Microsoft.\nsource:\rhttps://docs.microsoft.com/en-us/azure/cosmos-db/request-units\r\r\rM√™me en connaissant tout les facteurs il faut prendre en compte que la formule de calcul reste chez Microsoft, de ce fait il est tr√®s difficile de pr√©dire √† l\u0026rsquo;avance combien pr√©cis√©ment une requ√™te consomme en RU.\nN√©anmoins il est possible de conna√Ætre la consommation d\u0026rsquo;une requ√™te apr√®s l\u0026rsquo;avoir ex√©cut√©e et d\u0026rsquo;adapter en fonction en examinant l\u0026rsquo;en-t√™te x-ms-request-charge de la r√©ponse.\nCette donn√©e est aussi disponible via le portail lors de l\u0026rsquo;ex√©cution d\u0026rsquo;une requ√™te:\nEt directement via le SDK au travers de la propri√©t√© RequestCharge.\n1 2  var response = await conteneur.CreateItemAsync(foo, new PartitionKey(foo.Pk)); var ru = response.RequestCharge;   La fr√©quence La fr√©quence de lancement des requ√™tes est primordiale et aussi la plus compliqu√©e √† d√©terminer (nous n\u0026rsquo;allons ici pas parler des Bulk insert/update qui feront l\u0026rsquo;objet d\u0026rsquo;un autre article).\nSupposons le cas o√π vous ayez 50 requ√™tes √† 10 RU chacune, sur une provision √† 400 RU/s le lancement de toutes les requ√™tes en parall√®le provoquera des erreurs 429.\nDeux solutions sont possibles : augmenter temporairement le provisionnement ou lisser les requ√™tes dans le temps (par seconde).\nNous allons nous attarder sur la deuxi√®me solution: le lissage dans le temps n\u0026rsquo;a pas pour but de s√©quentialiser 1 √† 1 nos requ√™tes, ou faire 1 requ√™te par seconde, √ßa serait une catastrophe niveau performance et nous perdrions tout l\u0026rsquo;int√©r√™t de la puissance du parall√©lisme que nous offre Cosmos DB, l\u0026rsquo;objectif sera de trouver le bon compromis entre performance et usage selon notre contexte et nos ressources.\nIl faudra donc se poser la question suivante:\nCombien de RU puis-je consommer par seconde sans que cela ne provoque d\u0026rsquo;erreurs/latences ailleur dans mon application ?\rBien √©videmment il n\u0026rsquo;y a pas de r√©ponse universelle √† cette question, tout d√©pend de votre contexte (ressources / usages / fr√©quences\u0026hellip;).\nMais une fois la r√©ponse trouv√©e ou suppos√©ment trouv√©e voici une m√©thode d\u0026rsquo;extension que vous pouvez retrouver sur mon gist qui permet de limiter le nombre de t√¢che en parall√®le de mani√®re temporis√©e et ainsi r√©pondre par exemple au besoin: \u0026ldquo;je veux X traitements toutes les secondes\u0026rdquo;.\n 1 2 3 4 5 6 7 8 9  var maxDegreeOfParallelism = 10; // the RUs is limited by second. var millisecondsDelay = TimeSpan.FromSeconds(1).TotalMilliseconds; await Enumerable.Range(0, 50).DelayParallelForEachAsync(async (index) =\u0026gt; { var foo = Foo.Create(Guid.NewGuid().ToString()); await conteneur.CreateItemAsync(foo, new PartitionKey(foo.Pk)); }, maxDegreeOfParallelism, millisecondsDelay);   Recommencer La solution la plus simple et courante est tout simplement de relancer la requ√™te.\nEn effet en partant du principe que le conteneur n\u0026rsquo;est pas sous-provisionn√©, des erreurs 429 peuvent arriver occasionnellement lors d\u0026rsquo;une activit√© √† fort trafic.\nDans cette situation rien ne sert de sur-dimensionner le conteneur (et ainsi payer plus) pour √©viter un probl√®me qui intervient seulement quelques secondes dans la journ√©e.\nL\u0026rsquo;erreur HTTP 429 est accompagn√©e de l\u0026rsquo;en-t√™te x-ms-retry-after-ms qui indique dans combien de temps il sera possible de relancer la requ√™te.\nHeureusement cette logique de relancement est d√©j√† g√©r√©e par le SDK via la propri√©t√© MaxRetryAttemptsOnRateLimitedRequests\nLe nombre de nouvelles tentatives pour une requ√™te est par d√©faut de 9 sur le SDK.\r 1 2 3 4  CosmosClient cosmosClient = new CosmosClient(ConnectionString, new CosmosClientOptions() { MaxRetryAttemptsOnRateLimitedRequests = 30 });   Super donc je n\u0026rsquo;ai qu\u0026rsquo;√† mettre cette propri√©t√© √† 1 000 000 et le probl√®me est r√©gl√© !\rEn th√©orie oui‚Ä¶ mais dans la quasi-totalit√© des cas c\u0026rsquo;est une tr√®s mauvaise id√©e. En effet cr√©er un tr√®s grand nombre de tentative :\n augmente le d√©lai d\u0026rsquo;ex√©cution des requ√™tes (429 -\u0026gt; attendre 100ms -\u0026gt; 429 -\u0026gt; attendre 100ms -\u0026gt; [‚Ä¶] -\u0026gt; OK) peut provoquer des effets de bord tr√®s graves sur l\u0026rsquo;application (lenteurs, threads bloqu√©s, timeout‚Ä¶) fait office de cache mis√®re et ainsi masque le fait que votre conteneur est sous-provisionn√©  Concernant le nombre √† mettre, il n\u0026rsquo;y a pas de ‚Äúnombre magique‚Äù cela est √† adapter en fonction du besoin (Microsoft recommande n√©anmoins par exemple de passer cette valeur √† 30 durant l\u0026rsquo;insertion d\u0026rsquo;un grand nombre d\u0026rsquo;entit√©).\nAutoPilot En preview √† l\u0026rsquo;√©criture de cet article, Cosmos AutoPilot permet de mettre √† l\u0026rsquo;√©chelle automatiquement le conteneur selon une plage de RU donn√©e.\nIl faut n√©anmoins prendre en compte plusieurs aspects de AutoPilot:\n Il poss√®de sa propre tarification (plus √©lev√©e que le provisionn√©) Il n\u0026rsquo;emp√™che pas les 429 mais les limites fortement (dans l\u0026rsquo;illustration si vous d√©pass√© les 4000 RU/s les requ√™tes passeront en 429) A l\u0026rsquo;√©criture de l\u0026rsquo;article il n\u0026rsquo;est pas encore possible de provisionner un conteneur en AutoPilot via le SDK (mais ceci est pr√©vu)  Augmenter le provisionnement Si malgr√© toutes les actions pr√©c√©dentes des erreurs 429 apparaissent toujours et sont probl√©matiques, alors cela signifie simplement que votre conteneur est sous provisionn√©e par rapport √† votre besoin.\nPour aider √† choisir le provisionnement adapt√© Microsoft met √† disposition une calculatrice √† capacit√©: https://cosmos.azure.com/capacitycalculator/.\nConclusion Les erreurs HTTP 429 ne posent pas de probl√®mes tant qu\u0026rsquo;elles sont g√©r√©es et restent occasionnelles.\nElles doivent avant toute chose √™tre un point d\u0026rsquo;alerte pour se poser des questions sur les performances du code/requ√™tes et le provisionnement des conteneurs.\nSources Repository  https://gist.github.com/Golapadeog/7228a17b6287619f71ffd1ba60e4faa2  Documentation  https://docs.microsoft.com/en-us/azure/cosmos-db/performance-tips https://docs.microsoft.com/en-us/azure/cosmos-db/provision-throughput-autopilot https://docs.microsoft.com/en-us/azure/cosmos-db/autopilot-faq https://docs.microsoft.com/en-us/azure/cosmos-db/optimize-cost-queries https://docs.microsoft.com/en-us/azure/cosmos-db/request-units https://cosmos.azure.com/capacitycalculator/  ","description":"","id":16,"section":"posts","tags":["azure","dotnet","csharp","performance","cosmos"],"title":"[Azure] Comment g√©rer les erreurs 429 sur Azure Cosmos DB","uri":"https://blog.jeremylandon.com/fr/2020/04/06/azure-comment-gerer-les-erreurs-429-sur-azure-cosmos-db/"},{"content":"L\u0026rsquo;article a √©t√© mis √† jour suite √† un compl√©ment d\u0026rsquo;information fourni par le d√©veloppeur principal de TinyCsvParser, cf conclusion\rLe traitement d\u0026rsquo;un fichier csv de plusieurs Go peut vite √™tre co√ªteux en terme de performance.\nPour rappel un fichier csv n\u0026rsquo;est pas seulement un format qui s√©pare ses colonnes par un caract√®re, mais c\u0026rsquo;est aussi:\n des ent√™tes pr√©sentes ou non, des colonnes parfois inexistantes, des lignes vides, des guillemets pour repr√©senter une colonne, des guillemets dans des guillemets pour repr√©senter des guillemets dans une colonne‚Ä¶ ‚Ä¶  Bref, la liste est encore longue et √ßa peut vite devenir un vrai casse t√™te de g√©rer tous les cas.\nA cela s\u0026rsquo;ajoute qu\u0026rsquo;il faut la plupart du temps lier les colonnes √† des objets de notre code, que dans le cas d\u0026rsquo;un tr√®s gros fichier il n\u0026rsquo;est pas envisageable de charger le fichier en m√©moire et qu\u0026rsquo;il faudra lire √† m√™me le stream ce qui peut apporter d\u0026rsquo;autres probl√©matiques (heureusement en .NET cette derni√®re probl√©matique reste extr√™mement simple √† solutionner) cela peut devenir relativement compliqu√©.\nBien entendu d\u0026rsquo;autres se sont pris la t√™te l√†-dessus, c\u0026rsquo;est pour cette raison qu\u0026rsquo;il existe un grand nombre de framework de lecture/√©criture de fichier csv qui g√®re la totalit√© des probl√©matiques li√©es √† ce format.\nTextFieldParser Le framework .NET propose une solution de base avec TextFieldParser.\nSampleCsvParser\rFoo\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  [Benchmark] public void TextFieldParser() { using var streamReader = new StreamReader(_csvFilePath); TextFieldParser parser = new TextFieldParser(_csvFilePath) { HasFieldsEnclosedInQuotes = true, Delimiters = new[] { \u0026#34;,\u0026#34; } }; string[] fields; while ((fields = parser.ReadFields()) != null) { Foo.CreateFromFields(fields); // ...  } }   \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class Foo { public string Prop0 { get; set; } public string Prop1 { get; set; } public string Prop2 { get; set; } public static Foo CreateFromFields(string[] fields) { return new Foo { Prop0 = fields[0], Prop1 = fields[1], Prop2 = fields[2], }; } }   \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"06a85a490055e909\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r CsvHelper sources: https://github.com/JoshClose/CsvHelper\nSampleCsvParser\rFooMapping\r\r1 2 3 4 5 6 7 8 9 10 11 12 13  [Benchmark] public void CsvHelper() { using var streamReader = new StreamReader(_csvFilePath); var csvconfig = new CsvConfiguration(CultureInfo.CurrentCulture) { Delimiter = \u0026#34;,\u0026#34;, HasHeaderRecord = false }; csvconfig.RegisterClassMap\u0026lt;CsvHelperFooMapping\u0026gt;(); var csv = new CsvReader(streamReader, csvconfig); using var records = csv.GetRecords\u0026lt;Foo\u0026gt;().GetEnumerator(); while (records.MoveNext()) { // ...  } }   \r\r1 2 3 4 5 6 7 8 9  public sealed class CsvHelperFooMapping: ClassMap\u0026lt;Foo\u0026gt; { public CsvHelperFooMapping() { Map(x =\u0026gt; x.Prop0).Index(0); Map(x =\u0026gt; x.Prop1).Index(1); Map(x =\u0026gt; x.Prop2).Index(2); } }   \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"3d2c0ec2656c91d2\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r TinyCsvParser sources: https://github.com/bytefish/TinyCsvParser.\nSampleCsvParser\rFooMapping\r\r1 2 3 4 5 6 7 8 9 10 11  public void TinyCsvParser() { var csvParserOptions = new CsvParserOptions(false, \u0026#39;,\u0026#39;, Environment.ProcessorCount, false); var csvMapper = new TinyFooMapping(); var csvParser = new CsvParser\u0026lt;Foo\u0026gt;(csvParserOptions, csvMapper); using var records = csvParser.ReadFromFile(_csvFilePath, Encoding.UTF8).GetEnumerator(); while (records.MoveNext()) { // ...  } }   \r\r1 2 3 4 5 6 7 8 9  public sealed class TinyFooMapping : CsvMapping\u0026lt;Foo\u0026gt; { public TinyFooMapping() { MapProperty(0, x =\u0026gt; x.Prop0); MapProperty(1, x =\u0026gt; x.Prop1); MapProperty(2, x =\u0026gt; x.Prop2); } }   \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"cc6cbe517c96147d\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r R√©sultat (100 000 lignes + ssd)    Method Mean %     TextFieldParser 6,617.43 ms 0%   CsvHelper 4,018.37 ms -39 %   TinyCsvParser 1,062.29 ms -84 %    Doit-on d\u0026rsquo;office exclure CsvHelper?\nNon, comme toujours en d√©veloppement rien n\u0026rsquo;est blanc ou noir.\nDans ce cas sp√©cifique (un csv propre, une configuration de base et une lecture d\u0026rsquo;un gros fichier) TinyCsvParser est pr√©f√©rable en revanche dans d\u0026rsquo;autres sc√©narii CsvHelper apporte des fonctionnalit√©s tr√®s int√©ressantes (comme l\u0026rsquo;auto-mapping) qui peuvent faire gagner un pr√©cieux temps de d√©veloppement et de maintenance.\nBref cela d√©pend de la situation comme toujours.\nMais comment expliquer de tels d√©calages ? Principalement cela est d√ª au traitement des lignes du CSV pour g√©rer tous les cas et la cr√©ation des entit√©s.\nNous avons tendance √† se ruer sur des framework pour des choses simples, ces framework sont l√† pour g√©rer tous les cas ce qui apporte un confort de d√©veloppement, de la fiabilit√© mais malheureusement aussi une lourdeur dans les traitements.\nJ\u0026rsquo;ai r√©cemment d√ª parser un fichier de 30Go \u0026ldquo;propre\u0026rdquo; (virgule + parfois des guillemets) dont je connais parfaitement le format, et j\u0026rsquo;ai voulu voir combien co√ªte \u0026ldquo;la gestion de tous les cas\u0026rdquo;.\nSolution personnalis√©e SampleCsvParser\rExtractFields\r\r1 2 3 4 5 6 7 8 9 10 11  [Benchmark] public void Custom() { using var streamReader = new StreamReader(_csvFilePath); string line; while ((line = streamReader.ReadLine()) != null) { Foo.CreateFromCsvLine(line); // ...  } }   \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public class Foo { ... public static Foo CreateFromCsvLine(string line) { return CreateFromFields(ExtractFields(line, 3)); } private static string[] ExtractFields(string line, int propertyCount) { var result = new string[propertyCount]; var index = 0; bool isInQuotes = false; var chars = line.ToCharArray(); StringBuilder str = new StringBuilder(string.Empty); foreach (var t in chars) { if (t == \u0026#39;\u0026#34;\u0026#39;) { isInQuotes = !isInQuotes; } else if (t == \u0026#39;,\u0026#39; \u0026amp;\u0026amp; !isInQuotes) { result[index++] = str.ToString(); str.Clear(); } else { str.Append(t); } } result[index] = str.ToString(); return result; } }   \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"e004e7717029e56c\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r L\u0026rsquo;algorithme d\u0026rsquo;analyse des lignes csv est simple et limit√©e mais correspond √† mon besoin.\nEt voici le r√©sultat :\n   Method Mean %     TextFieldParser 6,617.43 ms 0%   CsvHelper 4,018.37 ms -39 %   TinyCsvParser 1,062.29 ms -84 %   Custom 1,083.97 ms -83 %    Comment TinyCsvParser peut-il encore √™tre plus performant ? Simplement car ce framework utilise de base le parall√©lisme. Nous allons en faire de m√™me pour la science.\nSolution personnalis√©e avec parall√©lisme SampleCsvParser\rStreamReaderEnumerator\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  [Benchmark] public void CustomParallel() { using var streamReader = new StreamReader(_csvFilePath); var enumerator = new StreamReaderEnumerable(streamReader); var po = new ParallelOptions { // just for demo  MaxDegreeOfParallelism = Environment.ProcessorCount }; var action = new Action\u0026lt;string\u0026gt;(line =\u0026gt; { Foo.CreateFromCsvLine(line); // ...  }); Parallel.ForEach(enumerator, po, action); }   \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  /// \u0026lt;summary\u0026gt; /// This method comes from \u0026lt;see href=\u0026#34;!:https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1.etenumerator\u0026#34;\u0026gt;msdn\u0026lt;/see\u0026gt; /// \u0026lt;/summary\u0026gt; public class StreamReaderEnumerable : IEnumerable\u0026lt;string\u0026gt; { private readonly StreamReader _sr; public StreamReaderEnumerable(StreamReader streamReader) { _sr = streamReader; } // Must implement GetEnumerator, which returns a new StreamReaderEnumerator.  public IEnumerator\u0026lt;string\u0026gt; GetEnumerator() { return new StreamReaderEnumerator(_sr); } // Must also implement IEnumerable.GetEnumerator, but implement as a private method.  private IEnumerator GetEnumerator1() { return GetEnumerator(); } IEnumerator IEnumerable.GetEnumerator() { return GetEnumerator1(); } } /// \u0026lt;summary\u0026gt; /// This method comes from \u0026lt;see href=\u0026#34;!:https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1.etenumerator\u0026#34;\u0026gt;msdn\u0026lt;/see\u0026gt; /// \u0026lt;/summary\u0026gt; public class StreamReaderEnumerator : IEnumerator\u0026lt;string\u0026gt; { private readonly StreamReader _sr; public StreamReaderEnumerator(StreamReader streamReader) { _sr = streamReader; } private string _current; // Implement the IEnumerator(T).Current publicly, but implement  // IEnumerator.Current, which is also required, privately.  public string Current { get { if (_sr == null || _current == null) { throw new InvalidOperationException(); } return _current; } } private object Current1 =\u0026gt; this.Current; object IEnumerator.Current =\u0026gt; Current1; // Implement MoveNext and Reset, which are required by IEnumerator.  public bool MoveNext() { _current = _sr.ReadLine(); return _current != null; } public void Reset() { _sr.DiscardBufferedData(); _sr.BaseStream.Seek(0, SeekOrigin.Begin); _current = null; } // Implement IDisposable, which is also implemented by IEnumerator(T).  private bool _disposedValue; public void Dispose() { Dispose(true); GC.SuppressFinalize(this); } protected virtual void Dispose(bool disposing) { if (!_disposedValue) { if (disposing) { // Dispose of managed resources.  } _current = null; if (_sr != null) { _sr.Close(); _sr.Dispose(); } } _disposedValue = true; } ~StreamReaderEnumerator() { Dispose(false); } }   \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"b74dbcb284efe091\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r    Method Mean %     TextFieldParser 6,617.43 ms 0%   CsvHelper 4,018.37 ms -39 %   TinyCsvParser 1,062.29 ms -84 %   Custom 1,083.97 ms -83 %   CustomParallel 632.97 ms -90 %    Le temps est divis√© par 2 par rapport √† TinyCsvParser. Au final, sur mon fichier de 30Go je suis pass√© de 7min √† 3min20 de traitement de mani√®re simple.\r Conclusion Les performances d\u0026rsquo;une solution personnalis√©e laissent r√™veur, n√©anmoins ce code ne r√©pond qu\u0026rsquo;√† un seul et unique cas: les tr√®s gros fichiers csv propre et simple.\nMais dans le cas o√π vous ayez un grand nombre de fichier csv avec des \u0026ldquo;qualit√©s\u0026rdquo; variables, \u0026ldquo;il est fortement recommand√©\u0026rdquo; de passer par un framework tel que CsvHelper ou TinyCsvParser o√π un grand nombre de bons d√©veloppeurs ont pu analyser les performances de chaque ligne de code permettant de g√©rer tout les cas.\nNB: Il est int√©ressant de se rendre compte que le classement est totalement chamboul√© sur des petits fichiers csv (exemple avec un csv de 10 lignes):\r   Method Mean %     TextFieldParser 253.18 us 0%   CsvHelper 991.40 us +291 %   TinyCsvParser 653.78 us +158 %   Custom 50.99 us -79 %   CustomParallel 113.25 us -55 %    Ce qui prouve encore qu\u0026rsquo;il n\u0026rsquo;y a pas de magie en d√©veloppement, que tout d√©pend du contexte et annexement que le parall√©lisme est tr√®s souvent profitable et recommand√© mais peut aussi √™tre un pi√®ge.\r Mise √† jour (06/08/2020) J\u0026rsquo;ai eu le plaisir d\u0026rsquo;avoir un retour volontaire du d√©veloppeur principal de TinyCsvParser, ce dernier apporte une solution int√©ressante pour utiliser le framework avec un analyseur personnalis√© (Tokenizer), vous pouvez voir plus de d√©tails directement sur le repo du projet ou l\u0026rsquo;exemple de ce post a √©t√© inclus et fournit plus de d√©tail sur comment son framework fonctionne.\nAu del√† de √ßa, son retour (pr√©sent ici) me fait revoir/nuancer le message de ce post.\nEn effet la r√©ponse pour savoir si oui ou non un framework est √† utiliser pour ce besoin sp√©cifique est plus compliqu√© que de premier abord (plus compliqu√© que beaucoup = framework / un cas = personnalis√© ou framework).\nJ\u0026rsquo;ai voulu dans un premier temps traiter le sujet ici, mais apr√®s r√©flexion beaucoup de param√®tres rentrent en jeu (le contexte, le budget, les comp√©tences, le risque, les resources, le besoin\u0026hellip;), cela fera l\u0026rsquo;objet d\u0026rsquo;un post annexe plus globale qui apportera non pas une r√©ponse (je pense que cela est impossible) mais un point de vue sur la question.\nSources Documentation  https://docs.microsoft.com/en-us/dotnet/api/microsoft.visualbasic.fileio.textfieldparser https://github.com/JoshClose/CsvHelper https://github.com/bytefish/TinyCsvParser https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1.getenumerator https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/potential-pitfalls-in-data-and-task-parallelism https://github.com/bytefish/TinyCsvParser/blob/master/TinyCsvParser/TinyCsvParser.Test/Integration/TokenizerBenchmark.cs https://github.com/Golapadeog/blog/issues/1  ","description":"","id":17,"section":"posts","tags":["dotnet","csharp","algorithm","performance","benchmark"],"title":"[.NET] Comment lire un tr√®s gros fichier csv","uri":"https://blog.jeremylandon.com/fr/2020/03/30/dotnet-comment-lire-un-tres-gros-fichier-csv/"},{"content":"Une des fa√ßons les plus simples et courantes d\u0026rsquo;utiliser les services de messagerie tels qu\u0026rsquo;Azure Service Bus est pour effectuer une communication unidirectionnel.\nsource:\rhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview\r\r\rExemple: Bob en tant qu\u0026rsquo;envoyeur de message et Eve en tant que r√©ceptionniste.\n1. Eve √©coute la file d\u0026rsquo;attente Q1\n2. Bob envoie un message sur Q1\n3. Eve re√ßoit le message de Bob √† partir Q1\nMais comment Bob peut-il savoir que le traitement de Eve est termin√© ?\nOu plus g√©n√©ralement comment ces 2 services peuvent-ils communiquer de mani√®re bidirectionnelle? C\u0026rsquo;est l√† que le pattern Request/Response (ou Request/Reply) intervient.\nLe pattern Request/Response Ce pattern utilise un routage de message afin d\u0026rsquo;obtenir une communication bidirectionnel entre deux services.\nFonctionnellement c\u0026rsquo;est tr√®s simple, l\u0026rsquo;envoyeur envoie un message sur une file d\u0026rsquo;attente et attend une r√©ponse sur une autre file d\u0026rsquo;attente.\nsource:\rhttps://www.enterpriseintegrationpatterns.com/patterns/messaging/RequestReplyJmsExample.html\r\r\rIl existe 4 types de routage principaux qui sont tr√®s bien d√©taill√©s ici : https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nDans la version \u0026ldquo;la plus simple\u0026rdquo; (Request/Response simple), il n\u0026rsquo;existe aucune garantie que Bob re√ßoit son message de r√©ponse. En effet si un nouvel utilisateur nomm√© Alice √©coute la m√™me file d\u0026rsquo;attente, elle pourrait intercepter le message destin√© √† Bob.\nConcurrence entre Bob et Alice:\r\r\rNaturellement une id√©e pourrait venir en t√™te assez rapidement : Bob cr√©√© une file d\u0026rsquo;attente √† lui et attend la r√©ponse dessus. Une fois la r√©ponse obtenue il supprime la file d\u0026rsquo;attente.\nC\u0026rsquo;est une logique correcte, mais qui n\u0026rsquo;est pas √† faire, car:\n elle implique une gestion des services morts (que faire si le processus crash sans avoir supprim√© son service ? Nous devons d√©velopper un cleaner en externe ? Doit-on supprimer le service avec les lettres mortes associ√©es qui fournissent de pr√©cisieuses informations pour r√©gler un potentiel bug ?\u0026hellip;) elle n\u0026rsquo;est √©videmment pas performante (il faudra √† chaque fois cr√©er et supprimer la queue, dans des fr√©quences parfois √©lev√©es) elle introduit une pollution du Service Bus Namespace qui le rend difficile/impossible √† analyser les Service Bus Namespace ont une limite sur la quantit√© de file d\u0026rsquo;attente/topic pouvant √™tre cr√©√© \u0026hellip;etc  En bref beaucoup de probl√®mes pour une solution personnalis√©e, et le standard est toujours √† privil√©gier. N\u0026rsquo;en existe-t-il pas un ?\nJustement si, grace au protocole AMQP qui apporte une notion de groupe, retranscrite chez Microsoft sous le nom session qui r√©sout tr√®s simplement et rapidement cette probl√©matique.\nLes sessions (groupe) Pour garantir que Bob soit le seul √† r√©cup√©rer le message de r√©ponse qui lui est destin√©, nous allons utiliser les sessions (ou plus pr√©cisement les groupes du protocole AMQP), qui pour faire simple apporte une multipl√©xage et ainsi plusieurs utilisateurs peuvent √©couter la m√™me file tout en ayant chacun leur propre groupe de message.\nBob √©coute et verrouille une session sp√©cifique sur la file d\u0026rsquo;attente, ainsi lui seul pourra √©couter ses messages (√† l\u0026rsquo;image d\u0026rsquo;une sous file d\u0026rsquo;attente r√©serv√©e √† Bob).\nBob devra fournir des informations suppl√©mentaires √† son message afin que le r√©ceptionneur (Eve) puisse envoyer correctement le message de r√©ponse.\nTechniquement cela se traduit par deux propri√©t√©s d√©finies par le protocole AMQP 1.0 :\nle nom des champs du protocole AMQP ne sont pas forcement les m√™mes que ceux de l\u0026rsquo;API (ex: group-id dans le protocole = SessionId dans l\u0026rsquo;API)\r  ReplyTo (reply-to): chemin d\u0026rsquo;acc√®s o√π Bob attend la r√©ponse. Eve y enverra son message de r√©ponse. ReplyToSessionId (reply-to-group-id): l\u0026rsquo;id de la session √©cout√©e par Bob. Eve assignera cette valeur √† la propri√©t√© SessionId (group-id) de son message de r√©ponse.  Exemple L\u0026rsquo;exemple sera r√©alis√© avec Microsoft.Azure.ServiceBus et de deux files d\u0026rsquo;attente.\nTechniquement il est indispensable que la file d\u0026rsquo;attente de r√©ponse n\u0026rsquo;accepte que les sessions.\nCela peut se faire via le portail Azure.\nsource:\rhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/message-sessions\r\r\rOu via le code avec la propri√©t√© RequiresSession.\n1 2 3 4 5  var managementClient = new ManagementClient(connectionString); await managementClient.CreateQueueAsync(new QueueDescription(queueName) { RequiresSession = true });   Creation des files d\u0026rsquo;attente Dans un premier temps nous allons cr√©er pour la d√©monstration 2 files d\u0026rsquo;attente:\n sample.request: sans session, utilis√©e pour envoyer les messages de Bob √† traiter par Eve. sample.retry: avec session, utilis√©e pour envoyer la r√©ponse √† Bob.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  static async Task Main() { var connectionString = \u0026#34;\u0026lt;your_connection_string\u0026gt;\u0026#34;; var requestQueueName = \u0026#34;sample.request\u0026#34;; var replyQueueName = \u0026#34;sample.reply\u0026#34;; // create queues  await Task.WhenAll(CreateQueueAsync(connectionString, requestQueueName, false), CreateQueueAsync(connectionString, replyQueueName, true)); } // /!\\ IT\u0026#39;S JUST FOR DEMO static async Task CreateQueueAsync(string connectionString, string queueName, bool requiresSession) { var managementClient = new ManagementClient(connectionString); if (await managementClient.QueueExistsAsync(queueName)) { await managementClient.DeleteQueueAsync(queueName); } await managementClient.CreateQueueAsync(new QueueDescription(queueName) { RequiresSession = requiresSession }); }   Pour la d√©monstration chaque service sera simul√© par un thread.\nThread de l\u0026rsquo;envoyeur (Bob) Bob envoie un message avec la propri√©t√© ReplyTo √©gal au chemin d\u0026rsquo;acc√®s de la file d\u0026rsquo;attente de r√©ponse et ReplyToSessionId √©gal √† l\u0026rsquo;identifiant de sa session.\nUne fois le message envoy√© Bob √©coute sa session.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public static class SampleThreadFactory { ... public static Thread CreateRequestor(string threadId, string connectionString, string requestQueueName, string replyQueueName) { return new Thread(async () =\u0026gt; { /*** send message ***/ var messageSender = new MessageSender(connectionString, requestQueueName); var sessionId = \u0026#34;session-\u0026#34; + threadId; var message = new Message { MessageId = threadId, ReplyTo = new ServiceBusConnectionStringBuilder(connectionString) { EntityPath = replyQueueName }.ToString(), ReplyToSessionId = sessionId, TimeToLive = TimeSpan.FromMinutes(2) }; await messageSender.SendAsync(message); await messageSender.CloseAsync(); /*** send message ***/ /*** wait response ***/ SessionClient sessionClient = new SessionClient(connectionString, replyQueueName); var session = await sessionClient.AcceptMessageSessionAsync(sessionId); Message sessionMessage = await session.ReceiveAsync(TimeSpan.FromMinutes(2)); await session.CompleteAsync(sessionMessage.SystemProperties.LockToken); await session.CloseAsync(); await sessionClient.CloseAsync(); /*** wait response ***/ }); } }   Thread du r√©pondeur (Eve) Eve √©coute la file d\u0026rsquo;attente sur laquelle Bob envoie ses messages.\nUne fois qu\u0026rsquo;un message est intercept√©, elle envoie un message de r√©ponse sur le chemin d\u0026rsquo;acc√®s d√©fini par la propri√©t√© ReplyTo.\nLe message de r√©ponse envoy√© doit contenir la propri√©t√© SessionId d√©finie √† partir la propri√©t√© ReplyToSessionId du message intercept√© (et pour le suivi ainsi qu\u0026rsquo;une standardisation, la propri√©t√© CorrelationId est √©gal √† l\u0026rsquo;id (MessageId) du message r√©ceptionn√©).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public static class SampleThreadFactory { public static Thread CreateReplier(string threadId, string connectionString, string requestQueueName) { return new Thread(() =\u0026gt; { var messageReceiver = new MessageReceiver(connectionString, requestQueueName); messageReceiver.RegisterMessageHandler( async (message, cancellationToken) =\u0026gt; { var connectionStringBuilder = new ServiceBusConnectionStringBuilder(message.ReplyTo); var replyToQueue = new MessageSender(connectionStringBuilder); var replyMessage = new Message(Encoding.UTF8.GetBytes($\u0026#34;processed by {threadId}\u0026#34;)) { CorrelationId = message.MessageId, SessionId = message.ReplyToSessionId, TimeToLive = TimeSpan.FromMinutes(1) }; /**** Simulate an action *****/ await Task.Delay(new Random().Next(1000, 2000), cancellationToken); /*******************************/ await replyToQueue.SendAsync(replyMessage); }, new MessageHandlerOptions(args =\u0026gt; throw args.Exception) { MaxConcurrentCalls = 10 }); }); }   Initialisation du contexte de test 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  static async Task Main() { var connectionString = \u0026#34;\u0026lt;your_connection_string\u0026gt;\u0026#34;; var requestQueueName = \u0026#34;sample.request\u0026#34;; var replyQueueName = \u0026#34;sample.reply\u0026#34;; // create queues  await Task.WhenAll(CreateQueueAsync(connectionString, requestQueueName, false), CreateQueueAsync(connectionString, replyQueueName, true)); // start all  Parallel.ForEach(new List\u0026lt;Thread\u0026gt; { SampleThreadFactory.CreateRequestor(\u0026#34;REQUESTOR-BOB\u0026#34;, connectionString, requestQueueName, replyQueueName), SampleThreadFactory.CreateReplier(\u0026#34;REPLIER-EVE\u0026#34;, connectionString, requestQueueName) }, (thread, state) =\u0026gt; thread.Start()); Console.Read(); }   R√©sulat Et aucun probl√®me avec plusieurs envoyeurs, chacun re√ßoit le message de r√©ponse qui lui est destin√©.\nVoil√†!\nSources Repository  https://github.com/Golapadeog/sample-azure-service-bus-request-response  Documentation  https://www.enterpriseintegrationpatterns.com/patterns/messaging/RequestReplyJmsExample.html https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-amqp-request-response https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads https://docs.microsoft.com/en-us/azure/service-bus-messaging/message-sessions https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-quotas https://en.wikipedia.org/wiki/Request%E2%80%93response https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html  ","description":"","id":18,"section":"posts","tags":["dotnet","csharp","azure","pattern"],"title":"[Azure] Pattern Request/Response avec Azure Service Bus","uri":"https://blog.jeremylandon.com/fr/2020/03/22/azure-pattern-request-response-avec-azure-service-bus/"},{"content":"Lors d\u0026rsquo;une tentative d\u0026rsquo;un copier/coller (pression longue) sur un champ Text sur IOS le message suivant peut apparaitre :\n\rThe getter \u0026lsquo;pasteButtonLabel\u0026rsquo; was called on null.\nReceiver: null\nTried calling: pasteButtonLabel\r Si tel est le cas, c\u0026rsquo;est qu\u0026rsquo;IOS n\u0026rsquo;arrive tout simplement pas √† trouver la localisation adapt√©e pour les boutons d\u0026rsquo;actions.\nPour corriger ce point il suffit de cr√©er un LocalizationsDelegate personnalis√© pour IOS :\n1 2 3 4 5 6 7 8 9 10 11 12  class CupertinoLocalisationsDelegate extends LocalizationsDelegate\u0026lt;CupertinoLocalizations\u0026gt; { const CupertinoLocalisationsDelegate(); @override bool isSupported(Locale locale) =\u0026gt; true; @override Future\u0026lt;CupertinoLocalizations\u0026gt; load(Locale locale) =\u0026gt; DefaultCupertinoLocalizations.load(locale); @override bool shouldReload(CupertinoLocalisationsDelegateold) =\u0026gt; false; }   Et de l\u0026rsquo;utiliser au niveau de la MaterialApp :\n1 2 3 4 5 6 7  MaterialApp( ... localizationsDelegates: const \u0026lt;LocalizationsDelegate\u0026lt;dynamic\u0026gt;\u0026gt;[ GlobalMaterialLocalizations.delegate, GlobalWidgetsLocalizations.delegate, + CupertinoLocalisationsDelegate(),  ], ...   A noter qu\u0026rsquo;avec cette classe la localisation utilis√©e pour les actions sera celle par d√©faut du t√©l√©phone.\nPour corriger ce point il faut modifier la logique de la m√©thode load(Local locale) qui permet de d√©finir la localisation.\r ","description":"Exception : The getter \"pasteButtonLabel\" was called on null","id":19,"section":"posts","tags":["flutter","dart","ios","mobile","exception"],"title":"[Flutter] Exception lors d'une copie sous IOS","uri":"https://blog.jeremylandon.com/fr/2019/10/21/flutter-throws-an-exception-when-trying-to-copy-on-ios/"}]